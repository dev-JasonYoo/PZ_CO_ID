# -*- coding: utf-8 -*-
"""PhotZ_LR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OYCdC4pXFnjTY4NHu2bub90vEjtFdUzt
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
import sys
import torch

drive.mount('/content/drive')
sys.path.append('/content/drive/MyDrive/Colab Notebooks')
sys.path.append('/content/drive/MyDrive/Colab Notebooks/src')

# %cd './drive/MyDrive/Colab Notebooks/src'
!ls ./

if torch.cuda.is_available():
  dev = "cuda:0"
  print(torch.cuda.device_count())
  print(torch.cuda.get_device_name(0))
else:
  dev = "cpu"

device = torch.device(dev)
print(f"The current device is: {device}")

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from pathlib import Path
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from torch.utils.data import TensorDataset, DataLoader
from torch.utils.data.dataset import random_split
from sklearn.preprocessing import MinMaxScaler
import plotting_routine as plotting
import json

class PhotZ_LR:
  '''Neural network linear regression that predicts photometric red shift values of galaxies

  method:
  __init__
  preprocess_data
  build_dl
  train_model
  evaulate_model
  save_results

  class:
  NeuralNetwork
  '''

  def __init__(self, **PhotZ_LR_config):
    self.num_input_features = PhotZ_LR_config["num_input_features"]
    self.num_hidden_neurons = PhotZ_LR_config["num_hidden_neurons"]
    self.num_hidden_layers = PhotZ_LR_config["num_hidden_layers"]
    self.num_epochs = PhotZ_LR_config["num_epochs"]
    self.learning_rate = PhotZ_LR_config["learning_rate"]
    self.size_batch = PhotZ_LR_config["size_batch"]
    self.momentum = PhotZ_LR_config["momentum"]

# more

  class NeuralNetwork(nn.Module):
    def __init__(self, num_input_features,
                num_hidden_neurons,
                num_hidden_layers):
      # Call __init__() of superclass (nn.Module)
      super(NeuralNetwork, self).__init__()
      # nn.Linear returns Tensor object (vector, matrix, tensor)
      self.input_layer = nn.Linear(num_input_features, num_hidden_neurons)
      # nn.ModuleLIst?
      self.hidden_layers = nn.ModuleList([nn.Linear(num_hidden_neurons, num_hidden_neurons) for n in range(num_hidden_layers - 1)])
      self.output_layer = nn.Linear(num_hidden_neurons, 1)

    # Define the computation performed in every cell
    def forward(self, x):
      x = torch.relu(self.input_layer(x))
      for hidden_layer in self.hidden_layers:
        x = torch.relu(hidden_layer(x))
      x = torch.relu(self.output_layer(x))
      return x

  def preprocess_data(self, Phot_Z_LR_config: dict):
    raw_df = pd.read_csv(PhotZ_LR_config['input_csv_path'])
    for key, val in PhotZ_LR_config.items():
      print(key, ':', val)

    scaler = MinMaxScaler()
    raw_df.iloc[:, :5] = pd.DataFrame(scaler.fit_transform(raw_df.iloc[:, :5]))

    raw_df = raw_df.iloc[:, :6]

    data = {"raw_df": raw_df}
    if PhotZ_LR_config["evaluation"]:
      eval_df = raw_df.sample(frac = PhotZ_LR_config["evaluation_ratio"])
      df = raw_df.drop(eval_df.index).sample(frac = 1.0)

      # Check
      print(f'''
      Length of raw data: {len(raw_df)}
      Length of evaluation data set: {len(eval_df)}
      Length of df (for training and test): {len(df)}
      {len(eval_df) + len(df)}
      Ratio: {len(eval_df)/len(raw_df)}
      Any duplicates?: {set(eval_df.index) & set(df.index)}''')

      data.update({"df": df, "eval_df": eval_df})

    else:
      df = raw_df.sample(frac = 1.0)

      data.update({"df": df})

    return data

  def build_dl(self, PhotZ_LR_config, data):
    # raw_df = df + eval_df
    raw_df = data["raw_df"]
    df = data["df"]
    eval_df = data["eval_df"]

    # Split data into F and T for raw_df
    raw_F = raw_df.iloc[:, 0:5]
    raw_T = raw_df.iloc[:, 5]

    raw_idx_tensor = torch.IntTensor(raw_F.index)
    raw_F_tensor = torch.FloatTensor(raw_F.values)
    raw_T_tensor = torch.FloatTensor(raw_T.values)

    raw_data = TensorDataset(raw_idx_tensor, raw_F_tensor, raw_T_tensor)

    # Split data into F and T for data
    F = df.iloc[:, 0:5]
    T = df.iloc[:, 5]

    idx_tensor = torch.IntTensor(F.index)
    F_tensor = torch.FloatTensor(F.values)
    T_tensor = torch.FloatTensor(T.values)

    FT_data = TensorDataset(idx_tensor, F_tensor, T_tensor)

    # Determine training and test sets
    train_size = int(len(df) * PhotZ_LR_config["train_ratio"])
    test_size = len(df) - train_size

    train_data, test_data = random_split(dataset = FT_data,
                                        lengths = [train_size, test_size])

    if PhotZ_LR_config["evaluation"]:
        # 5. Splitting evaluation dataframe into inputs and outputs dataset
        eval_F = eval_df.iloc[:, 0:5]
        eval_T = eval_df.iloc[:, 5]

        eval_idx_tensor = torch.IntTensor(eval_F.index)
        eval_F_tensor = torch.FloatTensor(eval_F.values)
        eval_T_tensor = torch.FloatTensor(eval_T.values)

        eval_data = TensorDataset(eval_idx_tensor, eval_F_tensor, eval_T_tensor)

    # Initialize DataLoader objects
    galaxy_dl = DataLoader(dataset = raw_data,
                      batch_size = PhotZ_LR_config['size_batch'],
                      shuffle = False)
    train_dl = DataLoader(dataset = train_data,
                          batch_size = PhotZ_LR_config["size_batch"],
                          shuffle = True)
    test_dl = DataLoader(dataset = test_data,
                          batch_size = PhotZ_LR_config["size_batch"],
                          shuffle = False)

    dl = {"galaxy_dl": galaxy_dl, "train_dl": train_dl, "test_dl": test_dl}
    if PhotZ_LR_config["evaluation"]:
        eval_dl = DataLoader(dataset = eval_data,
                                  batch_size = PhotZ_LR_config["size_batch"],
                                  shuffle = False)
        dl.update({"eval_dl": eval_dl})

    return dl

  def train_model(self, PhotZ_LR_config):
    # Initialize model
    model = NeuralNetwork(PhotZ_LR_config["num_input_features"],
                          PhotZ_LR_config["num_hidden_neurons"],
                          PhotZ_LR_config["num_hidden_layers"])

    # Define loss function and optimizer
    # Mean Sqaured Error loss function
    criterion = nn.MSELoss()
    # Stochastic Gradient Descent
    optimizer = optim.SGD(model.parameters(), lr = PhotZ_LR_config["learning_rate"], momentum = PhotZ_LR_config["momentum"])

    min_loss = 1 # why 1? what are the expected range of loss?
    best_model = None
    loss_data = []

    # Train the model
    num_epochs = PhotZ_LR_config["num_epochs"]
    for epoch in range(num_epochs):
      # Train
      for idx, inputs, targets in train_dl:
        # set p.grad to 0 where p is a parameter
        optimizer.zero_grad()
        outputs_pred = model(inputs)
        loss = criterion(outputs_pred, targets.unsqueeze(1))
        loss.backward()
        optimizer.step()
    #     if epoch%10 == 0: print(inputs, targets.unsqueeze(1), outputs_pred)

      # Record the minimum loss
      if loss < min_loss:
        min_loss = loss.item()
        best_model = model.state_dict()
        torch.save(best_model, PACKAGE_PATH / f'result/model_eval/PhotZ_LR_model_{PhotZ_LR_config["input_csv_path"].stem}_{PhotZ_LR_config["iteration"]}.pth')
        print('best model')

      # Print
      if ((epoch + 1)%10 == 0) or (loss == min_loss):
        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')
        loss_data.append(loss.item())
        print()

    return best_model

  def evaluate_model(self, PhotZ_LR_config):
    model_save_path = PhotZ_LR_config["PACKAGE_PATH"] / f'result/model_eval/PhotZ_LR_model_{PhotZ_LR_config["input_csv_path"].stem}_{PhotZ_LR_config["iteration"]}.pth'

    best_model = NeuralNetwork(PhotZ_LR_config['num_input_features'],
                              PhotZ_LR_config['num_hidden_neurons'],
                              PhotZ_LR_config['num_hidden_layers'])
    best_model.load_state_dict(torch.load(model_save_path))
    best_model.eval()

    with torch.no_grad():
        idx = []
        y_true = []
        y_pred = []

        for i, inputs, targets in dl["galaxy_dl"]:
            outputs = best_model(inputs)

            idx.extend(i.numpy())
            y_true.extend(targets.numpy())
            y_pred.extend(outputs.numpy())

    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    mse = mean_squared_error(y_true, y_pred)
    results_temp = pd.DataFrame({
        'idx': idx,
        'Spec z': y_true,
        'Phot z': y_pred.squeeze(),
        'mse': mse
    })

    results_temp.set_index('idx', inplace = True)
    results_temp.index.name = None
    results = pd.concat([data["raw_df"].iloc[:, :5], results_temp], axis = 1)

    return results

  def save_results(self, PhotZ_LR_config, results):
    results.to_csv(PhotZ_LR_config['output_csv_path'] / f'results_PhotZ_LR_{PhotZ_LR_config["input_csv_path"].stem}_{PhotZ_LR_config["iteration"]}.csv', index = False)

    fig = plt.figure(figsize = (7,7))
    axes = plt.subplot(1,1,1)
    plotting.plotpzsz(results['Phot z'], results['Spec z'])

    fig.text(0, -0.1, results["mse"][0])

    fig.savefig(PhotZ_LR_config['output_csv_path'] / f'results_PhotZ_LR_{PhotZ_LR_config["input_csv_path"].stem}_{PhotZ_LR_config["iteration"]}.pdf', format="pdf", bbox_inches="tight")

if __name__ == '__main__':

  with open("./model_config.json", "r") as f:
      json_dict = json.load(f)
      PACKAGE_PATH = Path(json_dict["PACKAGE_PATH"])
      PhotZ_LR_config = json_dict["model"]["PhotZ_LR"]


  PhotZ_LR_config.update({
      "input_csv_path": PACKAGE_PATH / 'data/rel_z.csv',
      "model_path": PACKAGE_PATH / 'result/model_eval/',
      "output_csv_path": PACKAGE_PATH / 'result/final/',
      "evaluation": True,
      "evaluation_ratio": 0.3,
      "train_ratio": 0.999,
      "PACKAGE_PATH": PACKAGE_PATH,
      "num_input_features": 5,
      "iteration": 0
  })

  PhotZ_LR_config["num_epochs"] = 10

  for i in range(3):
    PhotZ_LR_config["iteration"] += 1

    PhotZ_LR_model = PhotZ_LR(**PhotZ_LR_config)

    data = PhotZ_LR_model.preprocess_data(PhotZ_LR_config)
    dl = PhotZ_LR_model.build_dl(PhotZ_LR_config, data)
    best_model = PhotZ_LR_model.train_model(PhotZ_LR_config)
    results = PhotZ_LR_model.evaluate_model(PhotZ_LR_config)
    PhotZ_LR_model.save_results(PhotZ_LR_config, results)