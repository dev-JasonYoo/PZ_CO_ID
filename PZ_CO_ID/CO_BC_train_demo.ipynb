{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1e215c",
   "metadata": {},
   "source": [
    "# Demonstration: Training the binary clasification model\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eff25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from CO_BC import CO_BC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780d072b",
   "metadata": {},
   "source": [
    "### Import default configurations\n",
    "model_config.json has default hyperparameters for models: \n",
    "* the number of input features\n",
    "* the nubmer of hidden neurons for each layer\n",
    "* the nubmer of hidden layers\n",
    "* the nubmer of training epochs\n",
    "* learning rate\n",
    "* batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac14d9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_input_features': 0,\n",
       " 'num_hidden_neurons': [128, 256, 8],\n",
       " 'num_hidden_layers': 3,\n",
       " 'num_epochs': 300,\n",
       " 'learning_rate': 0.001,\n",
       " 'size_batch': 32}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PACKAGE_PATH = Path.cwd()\n",
    "with open(PACKAGE_PATH / \"model_config.json\", \"r\") as f:\n",
    "    json_dict = json.load(f)\n",
    "    CO_BC_config = json_dict[\"model\"][\"CO_BC\"]\n",
    "CO_BC_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a55131b",
   "metadata": {},
   "source": [
    "## Update the config\n",
    "\n",
    "Input/output paths and training-specific hyperparameters should be updated before traning\n",
    "\n",
    "* Input paths\n",
    "    * \"input_csv_path_pdf\": the path of the input csv file of redshift probability distribution\n",
    "    * \"input_csv_path_photz\": the path of the input csv file of photometric redshift\n",
    "* Output paths\n",
    "    * \"output_pdf_path\": the path of the output PDF extension file for saving plots and statistics\n",
    "    * \"output_csv_path\": the path of the output csv file for saving predictions\n",
    "    * \"model_path\": the path of the bese model to be saved\n",
    "\n",
    "* Training-specific hyperparameters\n",
    "    * CO_ratio\n",
    "    * weights: written in the format of [[range...], [weights...]]\n",
    "    * train_ratio: the ratio of a training set -- a value in between 0 and 1\n",
    "    * evaluation_ratio: the ratio of a base evaluation set -- a value in between 0 and 1\n",
    "    * evaluatoin: perform evaluation if set to True\n",
    "\n",
    "* Misc\n",
    "    * model_no: model number (not a hyperparameter) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "156115df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"model_CO_BC_hsc_SPIDERz_SPIDERz\"\n",
    "\n",
    "CO_BC_config.update({\n",
    "    \"input_csv_path_PDF\": PACKAGE_PATH / 'data/hsc_EPDF_all.csv',\n",
    "    \"input_csv_path_photz\": PACKAGE_PATH / 'data/hsc_EPDF_all.csv',\n",
    "    \"output_pdf_path\": PACKAGE_PATH / f'results/results_{model_name}.pdf',\n",
    "    \"output_csv_path\": PACKAGE_PATH / f'results/results_{model_name}.csv',\n",
    "    \"model_path\": PACKAGE_PATH / f'trained_model/CO_BC/{model_name}.pth',\n",
    "\n",
    "    # more hyperparamters\n",
    "    \"CO_ratio\": 0.1,\n",
    "    \"weights\": [[1, 2], [2, 45]],\n",
    "    \"train_ratio\": 0.99,\n",
    "\n",
    "    \"evaluation_ratio\": 0.3,\n",
    "    \"evaluation\": True,\n",
    "    \"model_no\": 0,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3b5fe",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "\n",
    "Result of training is printed out and saved in PDF and CSV during the `CO_BC.save_results()` function call\n",
    "\n",
    "\"model_no\" is incremented by 1 every loop of trianing, which is specified in the file names of a saved model and a result file, which can be found in `PZ_CO_ID/PZ_CO_ID/results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d03c645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\data\\유상현\\data\\2024-2025 Summer Research\\github\\PZ_CO_ID\\PZ_CO_ID\\CO_BC.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['Phot z'] = photz_df['Phot z']\n",
      "d:\\data\\유상현\\data\\2024-2025 Summer Research\\github\\PZ_CO_ID\\PZ_CO_ID\\CO_BC.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_df['CO?'] = np.zeros(len(raw_df), dtype = int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Length of raw data: 286401\n",
      "            Length of evaluation data set: 85920\n",
      "            Length of df (for training and test): 200481\n",
      "            286401\n",
      "            Ratio: 0.2999989525176239\n",
      "            Any duplicates?: set()\n",
      "best model\n",
      "Epoch [1/300], Loss: 0.412939310074\n",
      "\n",
      "best model\n",
      "Epoch [4/300], Loss: 0.045202732086\n",
      "\n",
      "best model\n",
      "Epoch [9/300], Loss: 0.019339719787\n",
      "\n",
      "Epoch [10/300], Loss: 0.122658342123\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m CO_BC_model\u001b[38;5;241m.\u001b[39mpreprocess_data()\n\u001b[0;32m      7\u001b[0m dl \u001b[38;5;241m=\u001b[39m CO_BC_model\u001b[38;5;241m.\u001b[39mbuild_dl(data)\n\u001b[1;32m----> 8\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mCO_BC_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m results \u001b[38;5;241m=\u001b[39m CO_BC_model\u001b[38;5;241m.\u001b[39mevaluate_model(data, dl)\n\u001b[0;32m     10\u001b[0m CO_BC_model\u001b[38;5;241m.\u001b[39msave_results(data, results)\n",
      "File \u001b[1;32md:\\data\\유상현\\data\\2024-2025 Summer Research\\github\\PZ_CO_ID\\PZ_CO_ID\\CO_BC.py:270\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(self, dl)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# Print\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (loss \u001b[38;5;241m==\u001b[39m min_loss):\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.12f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    272\u001b[0m     loss_data\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32md:\\data\\유상현\\data\\2024-2025 Summer Research\\github\\PZ_CO_ID\\PZ_CO_ID\\CO_BC.py:259\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, inputs, targets, zs, optimizer, weights)\u001b[0m\n\u001b[0;32m    256\u001b[0m train_dl \u001b[38;5;241m=\u001b[39m dl[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_dl\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, inputs, targets, zs \u001b[38;5;129;01min\u001b[39;00m train_dl:\n\u001b[0;32m    260\u001b[0m         loss \u001b[38;5;241m=\u001b[39m train(model, inputs, targets, zs, optimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;66;03m# Record the minimum loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1): # change the number to train models for multiple times\n",
    "    CO_BC_config[\"model_no\"] += 1\n",
    "\n",
    "    CO_BC_model = CO_BC(**CO_BC_config)\n",
    "\n",
    "    data = CO_BC_model.preprocess_data()\n",
    "    dl = CO_BC_model.build_dl(data)\n",
    "    best_model = CO_BC_model.train_model(dl)\n",
    "    results = CO_BC_model.evaluate_model(data, dl)\n",
    "    CO_BC_model.save_results(data, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9364611",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
